{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語と単語の分散表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自然言語とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の意味\n",
    "\n",
    "コンピュータに「単語の意味」を理解させるには、つまり「単語の意味」をコンピュータ上でうまく表現する方法について3つ手段を考える. \n",
    "\n",
    "1. シソーラス（類語辞典）による手法\n",
    "2. カウントペースの手法\n",
    "3. 推論ベースの手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シソーラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然言語処理におけるシソーラスは単に類語辞典にとどまらない. 一般には単語間における「上位と下位」、「全体と部分」といった関係性についても表現がされている. 具体的にはグラフ構造によって単語の関係を管理している. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も有名なシソーラスはWordNetである. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シソーラスの問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 時代の変化に対応するのが困難\n",
    "2. 人のコストが高い\n",
    "3. 単語の細かなニュアンスを表現できない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウントベースの手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントベース手法で分析を行うには「コーパス」が必要である。コーパスとは、アプリケーションを想定して目的を持って収集されたテキストデータである。テキストデータには目的に関する人間の知恵が反映されていると考えられるため、エッセンスを抽出できれば有用となる. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pythonによるコーパスの下準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然言語処理で用いられるコーパスにはさまざまなものが存在します。例えばWikipedia, Google Newsです. 夏目漱石やシェークスピアといった偉大な作家の作品についてもコーパスとして利用されている.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1文しかないがコーパスをつくる\n",
    "text = \"You say goodbye and I say hello.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# コーパスに対する前処理\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語をテキストのまま操作するのは不便であるので、単語にＩＤを振って、ＩＤのリストとして処理が進められるように前処理を行う. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 6, 'and': 3, 'goodbye': 2, 'hello': 5, 'i': 4, 'say': 1, 'you': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパス処理を関数化したpreprocessを使う\n",
    "import numpy as np\n",
    "from pynet.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_int, id_to_word = preprocess(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 6, 'and': 3, 'goodbye': 2, 'hello': 5, 'i': 4, 'say': 1, 'you': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の分散表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "色は「コバルトブルー」という名前が付いているが、ＲＧＢという3変数の値で表現することもできる。これは同じ色を別の単語で表現するしている場合にも判断がしやすく、知らない単語で表現された場合においてもどのような色であるのかを判断することが可能である. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然言語処理の単語でも同様にベクトルを用いた表現が可能ではないのか？我々が目指しているのは単語の意味を的確に捉えたベクトル表現である。これは自然言語処理の分野では、単語の**分散表現**と呼ばれている. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分布仮説"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 単語の意味は、周囲の単語によって形成される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから先、「コンテキスト」と表現した場合にはある単語の周囲にある単語を指すとする。そしてある単語からどの程度離れている単語までを見るのかを「ウィンドウサイズ」と表現する。例えば「you say goodbye and i sa hello.」のgoodbyeのウィンドウサイズ1のコンテキストはsay, andの2つである. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共起行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分布仮説に基づいて単語をベクトルで表現する方法として、周囲の単語を「カウント」することを考える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pynet.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_int, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の結果より、ここでは語彙数が全部で7個あることがわかる。\n",
    "\n",
    "それぞれの単語についてコンテキストに含まれる単語の頻度を数えていく. つまり、注目の単語x(コンテキスト)でクロステーブルを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数えた結果\n",
    "# ex) 2行目はsayであり, you, goodbye列にカウントがされている\n",
    "C = np.array([\n",
    "[0, 1, 0, 0, 0, 0, 0],\n",
    "[1, 0, 1, 0, 1, 1, 0],\n",
    "[0, 1, 0, 1, 0, 0, 0],\n",
    "[0, 0, 1, 0, 1, 0, 0],\n",
    "[0, 1, 0, 1, 0, 0, 0],\n",
    "[0, 1, 0, 0, 0, 0, 1],\n",
    "[0, 0, 0, 0, 0, 1, 0],\n",
    "], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベクトル間の類似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般には**コサイン類似度**が用いられる. \n",
    "\n",
    "$$\n",
    "    \\textrm{similarity}(x,y)=\\frac{x\\cdot y}{\\|x\\|\\|y\\|} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynet.util import preprocess, create_co_matrix, cos_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "text ='You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(c1\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類似単語のランキングの表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88788657,  1.10435083, -1.20129306, -0.60136768, -0.8138001 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 値が小さい順の要素インデックス\n",
    "a.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.20129306 -0.8138001  -0.60136768  0.88788657  1.10435083]\n"
     ]
    }
   ],
   "source": [
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynet.util import preprocess, create_co_matrix, cos_similarity, most_similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カウントベースの手法の改善"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相互情報量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "純粋なカウントベースは、無意味な情報も取得してしまう。例えばThe Carという単語が出てきた場合に、Theがよく用いられるばかりにTheとCarの関連性が大きいという意味のない結果となってしまう. そこで**相互情報量**という指標を用いる. \n",
    "\n",
    "式を見ると単独での出現率が低い単語で、共起した場合には値が大きくなるようだ. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{PMI(x,y)} =\\log_2\\frac{P(x,y)}{P(x)P(y)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般に$P(x,y)$はゼロになり得るため$\\textrm{PPMI} = \\textrm{max}\\{\\textrm{PMI}(x,y),0\\}$として置く. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pynet.util import preprocess, create_co_matrix, cos_similarity, most_similar, ppmi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance matrix\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "np.set_printoptions(precision=3) # 有効桁3桁で表示\n",
    "print('covariance matrix')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 次元削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の例ではほとんどの要素がゼロである。これらはノイズとなり、重要な情報を見失う結果となる. そこで次元削除という考え方がある. つまり固有値分解や特異値分析をおこなっていく. \n",
    "\n",
    "$$\n",
    "X = USV^{T}\n",
    "$$\n",
    "\n",
    "$U$は直行行列であり、列空間を表現している。そして$S$には列ベクトルの重要度を表現する特異値が入力されている. 特異値に一定の閾値を設けることで、重要な列ベクトルだけを抽出することが可能となる. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVDによる次元削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pynet.util import preprocess, create_co_matrix, ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.abs'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(id_to_word)\n",
    "C = create_co_matrix(corpus, vocab_size, windows_size = 1)\n",
    "W = ppmi(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD decomposition\n",
    "U, S, V = np.linalg.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0] [0.        1.8073549 0.        0.        0.        0.        0.       ] [-3.4094876e-01 -1.1102230e-16 -3.8857806e-16 -1.2051624e-01\n",
      "  0.0000000e+00  9.3232495e-01  2.2259700e-16]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    C[0], # 共起行列\n",
    "    W[0], # PPMI行列\n",
    "    U[0], # SVD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f68b8f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2次元のベクトルに削減してからグラフプロットする. \n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U[:,0], U[:,1], alpha = .5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般にＳＶＤはデータサイズNの３乗に比例するため自然言語処理では破綻しやすい。そこで、打ち切りSVDという小さな特異値を無視することで高速化を実現した手法がとられる. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTBデータセット\n",
    "\n",
    "本格的なコーパスを利用する. PTBは自然言語処理のベンチマークとしてよく利用される. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"deep-learning-from-scratch-2\")\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "print('corpus size:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTBデータセットでの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"deep-learning-from-scratch-2\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pynet.util import preprocess, create_co_matrix, ppmi, most_similar\n",
    "from dataset import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "wordvec_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting co-occurrence ...\n",
      "calculating PPMI ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinya\\Dropbox\\Python\\W\\DeepLearningScratch2\\pynet\\util.py:91: RuntimeWarning: overflow encountered in long_scalars\n",
      "  pmi = np.log2(C[i,j] * N / (S[j] * S[i]) + eps)\n",
      "C:\\Users\\shinya\\Dropbox\\Python\\W\\DeepLearningScratch2\\pynet\\util.py:91: RuntimeWarning: invalid value encountered in log2\n",
      "  pmi = np.log2(C[i,j] * N / (S[j] * S[i]) + eps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "100.0% done\n",
      "calculating SVD ...abs\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('counting co-occurrence ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose = True)\n",
    "\n",
    "print ('calculating SVD ...abs')\n",
    "try:\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(\n",
    "        W, \n",
    "        n_components = wordvec_size, \n",
    "        n_iter = 5,\n",
    "        random_state=None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " i: 0.6435355544090271\n",
      " we: 0.5660431385040283\n",
      " do: 0.5437111854553223\n",
      " anybody: 0.5300085544586182\n",
      " if: 0.47720038890838623\n",
      "\n",
      "[query] year\n",
      " month: 0.6472570896148682\n",
      " quarter: 0.6443499326705933\n",
      " last: 0.6038984060287476\n",
      " earlier: 0.584826648235321\n",
      " next: 0.5673558712005615\n",
      "\n",
      "[query] car\n",
      " auto: 0.619389533996582\n",
      " luxury: 0.5517598986625671\n",
      " vehicle: 0.5475897789001465\n",
      " cars: 0.5011576414108276\n",
      " corsica: 0.44716912508010864\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.7545796632766724\n",
      " nissan: 0.6819114685058594\n",
      " motors: 0.6336272954940796\n",
      " honda: 0.6123921871185303\n",
      " mazda: 0.5970044136047363\n"
     ]
    }
   ],
   "source": [
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_wod, word_vecs, top = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "納得いく類型化ができているように見える. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
