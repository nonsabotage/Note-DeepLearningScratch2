{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vecの高速化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 何もかも知ろうとしてくろうはするな。\n",
    "> さもなと、何ひとつ覚えられない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前章のシンプルな実装ではコーパスで扱う語彙数が増えると実用に耐えない。そこでEmbeddingレイヤと、Negative Samplingという損失関数を導入する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vecの改良1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "前章のプログラムでは語彙数が7であったが、実際には100万ということも珍しくない. 100万の行列に対する各レイヤーでの行列積の演算に多くの時間が必要となる. 具体的に指摘すると次の2点がボトルネックである. \n",
    "\n",
    "- 入力層のone-hot表現と重み行列$W_{in}$の行列積\n",
    "- 中間層と重み行列$W_{out}$の行列積\n",
    "\n",
    "前者はEmbeddingレイヤを導入することで解決する。後者をNegative Sampling損失関数で解決する. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddingレイヤ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よく考えてみるとone-hotベクトルと、重み行列の積は行を抽出していることと同じである. そのため素直に行列積を実装したMatMulレイヤを使う必要はないのである. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddingレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14],\n",
       "       [15, 16, 17],\n",
       "       [18, 19, 20]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpyの挙動を確認\n",
    "import numpy as np\n",
    "W = np.arange(21).reshape(7,3)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5],\n",
       "       [ 0,  1,  2],\n",
       "       [ 9, 10, 11],\n",
       "       [ 0,  1,  2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.array([1, 0, 3, 0])\n",
    "W[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vecの改良2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中間層以降の計算の問題点\n",
    "\n",
    "中間層で計算を減らしたとしても、スコア値は語彙数分だけ必要となるし、ソフトマックスには指数があるため計算には非常にコストがかかる. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多値分類から二値分類へ\n",
    "\n",
    "Negative samplingでは「二値分類」がキーアイディアである。つまり、語彙数分計算する多値問題を二値問題に変換（近似）できれば計算量を削減することができる。重み行列では特定の単語に対する値を抽出し、スコアが求められれば良い. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### シグモイド関数と交差エントロピー誤差\n",
    "\n",
    "二値問題として解くにはスコアにシグモイド関数を適用する。損失関数には交差エントロピーを使う。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多値分類から二値問題へ（実装編）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二値問題に変換できれば負例については適度に学習させることができる。つまり、ある入力における出力がその正解と比べるだけでなく、間違いを間違いとして判定できるように学習させることである。これによりすべてを学習させることがないので、計算量を減らすことが可能である。\n",
    "\n",
    "学習させる負例は10個程度である。ランダムに決めるのではなく、コーパスにおける頻度を見て決めることが多い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpyにおけるrandomな選択\n",
    "import numpy as np\n",
    "np.random.choice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'say', 'goodbye', 'I', 'say', 'hello.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 候補のなからからサンプリング\n",
    "words = 'You say goodbye I say hello.'.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['say', 'say', 'hello.', 'You', 'goodbye'], dtype='<U7')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words, size =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['say', 'hello.', 'goodbye', 'I', 'say'], dtype='<U7')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words, size = 5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分布に従ってサンプリング\n",
    "p = [.5, .1, .05, .2, .05, .1]\n",
    "np.random.choice(words, p = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
